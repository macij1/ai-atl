\section{Introduction}
\label{sec:intro}
As end-to-end architectures based on neural networks became the tool of choice
for processing speech and language, there has been increased interest in
techniques for analyzing and interpreting the representations emerging in these
models. A large array of analytical techniques have been proposed and applied
to diverse tasks and architectures
\citep{belinkov2019analysis,alishahi2019analyzing}.

Given the fast development of analysis techniques for NLP and speech processing
systems, relatively few systematic studies have been conducted to compare the
strengths and weaknesses of each methodology and to assess the reliability and
explanatory power of their outcomes in controlled settings.  This paper reports
a step in this direction: as a case study, we examine the representation of
phonology in neural network models of spoken language. We choose three
different models that process speech signal as input, and analyze their learned
neural representations.

We use two commonly applied analytical techniques: (i) {\it diagnostic models}
and (ii) {\it representational similarity analysis} to quantify to what extent
neural activation patterns encode phonemes and phoneme sequences.

In our experiments, we manipulate two important factors that can affect the
outcome of analysis. One pitfall not always successfully avoided in work on
neural representation analysis is the {\it role of learning}. Previous work has
shown that sometimes non-trivial representations can be found in the activation
patterns of randomly initialized, untrained neural networks
\citep{DBLP:journals/corr/abs-1809-10040,chrupala-alishahi-2019-correlating}.
Here we investigate the representations of phonology in neural models of spoken
language in light of this fact, as extant studies have not properly controlled
for role of learning in these representations.

The second manipulated factor in our experiments is the {\it scope of the
extracted neural activations}. We control for the temporal scope, probing both
local activations corresponding to a few milliseconds of the speech signal, as
well as global activations pooled over the whole utterance.

When applied to global-scope representations, both analysis methods detect
a robust difference between the trained and randomly initialized
target models. However we find that in our setting, RSA applied to
local representations shows low correlations between phonemes and
neural activation patterns for both trained and randomly initialized
target models, and for one of the target models the local diagnostic
classifier only shows a minor difference in the decodability of
phonemes from randomly initialized versus trained network. This
highlights the importance of reporting analysis results with randomly
initialized models as a baseline.

This paper comes with a repository which contains instructions and
code to reproduce our experiments.\footnote{See \href{https://github.com/gchrupala/analyzing-analytical-methods}{https://github.com/gchrupala/analyzing-analytical-methods}.}
