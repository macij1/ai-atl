\subsection{Results of the Proposed Image Data Generation Technique}
\label{sec:results_perturb}
%\newcolumntype{H}[1]{>{\centering\arraybackslash}m{0.8cm}}
\newcommand{\V}[1]{\parbox[c]{0.25cm}{\includegraphics[scale=0.5]{figures/#1}}}
\newcommand{\W}[1]{\parbox[c]{0.3cm}{\includegraphics[scale=0.5]{figures/#1}}}

In this section, we present the results of the decoder re-training technique and the new image data generation by perturbation technique proposed in Section \ref{sec:meth_perturb}. We evaluate the success as well as the limitations of the two techniques by referring to these results. 

Fig.\ref{fig:unsharp1} (a) illustrates several sample images from the EMNSIT-balanced test set and (b) illustrates the corresponding reconstructed images by $M_{1,dec}$, which was trained using 200 training samples per class. Fig. \ref{fig:unsharp1} (c) illustrates the corresponding reconstructions by $\widetilde{M}_{1,dec}$, which was obtained by re-training $M_{1,dec}$ using the proposed technique. It is evident that reconstructions by $\widetilde{M}_{1,dec}$ are much sharper than those by $M_{1,dec}$. Therefore, our proposed decoder re-training technique is highly successful in sharpening the character reconstruction. 

\begin{figure}[!h]
\vspace{-2mm}
\centering
\footnotesize
\begin{tabular}{p{2.4cm}cccccccc} 
 %\hline

%	Model & (l,p,r)	& (l,p,r)& (l,p,r)& (l,p,r)& (l,p,r)& (l,p,r)& (l,p,r)& (l,p,r)\\[0.5ex]  
% \vspace*{-0.5cm} \hline
(a) Test image & \V{final_test/good_6_ori.png} & \V{final_test/good_7_ori.png}& \V{final_test/good_51_ori.png}& \V{final_test/good_114_ori.png} & \V{final_test/good_75_ori.png} & \V{final_test/good_318_ori.png} & \V{final_test/good_96_ori.png} & \V{final_test/good_261_ori.png}\\
 \cline{1-1}

(b) Recon by $M_{1,\mathrm{dec}}$ & \V{final_ori/good_6_ori.png} & \V{final_ori/good_7_ori.png}& \V{final_ori/good_51_ori.png}& \V{final_ori/good_114_ori.png} & \V{final_ori/good_75_ori.png} & \V{final_ori/good_318_ori.png} & \V{final_ori/good_96_ori.png} & \V{final_ori/good_261_ori.png}\\
 \cline{1-1}

(c) Recon by $\widetilde{M}_{1,\mathrm{dec}}$ & \V{final_ori_sharped/good_6_ori.png} & \V{final_ori_sharped/good_7_ori.png}& \V{final_ori_sharped/good_51_ori.png}& \V{final_ori_sharped/good_114_ori.png} & \V{final_ori_sharped/good_75_ori.png} & \V{final_ori_sharped/good_318_ori.png} & \V{final_ori_sharped/good_96_ori.png} & \V{final_ori_sharped/good_261_ori.png}\\
%  \cline{1-1}  

%With perturbation & \V{final_per_sharped/good_6_ori.png} & \V{final_per_sharped/good_7_ori.png}& \V{final_per_sharped/good_51_ori.png}& \V{final_per_sharped/good_114_ori.png} & \V{final_per_sharped/good_75_ori.png} & \V{final_per_sharped/good_25_ori.png} & \V{final_per_sharped/good_96_ori.png} & \V{final_per_sharped/good_261_ori.png}\\
%\vspace*{0.05cm}
%\hline

\end{tabular}
\caption{Results of the decoder re-training technique}
\label{fig:unsharp1}
\vspace{-2mm}
\end{figure}

Even though the proposed decoder re-training technique is highly succesful in sharpening the reconstruction, it still does not capture the subtle variations of the input images expected from a succesful reconstruction. Hence, we perform the new image data generation by perturbation technique on the images reconstructed by $\widetilde{M}_{1,\mathrm{dec}}$. Fig. \ref{fig:pertub1} illustrates our results. Fig. \ref{fig:pertub1} (a) and (b) are identical to that of Fig. \ref{fig:unsharp1} (a) and (b), which we include for  comparison. Fig. \ref{fig:pertub1} (c) illustrates the corresponding results obtained by $\widetilde{M}_{2,\mathrm{dec}}$, which was trained afresh using the new dataset generated by the proposed technique. It is evident that reconstructions by $\widetilde{M}_{2,\mathrm{dec}}$ now captures the subtle variations that we required ---curvature of E, slanting of B, asymmetry of X---, and are much closer to the test image than the reconstruction by $M_{1,\mathrm{dec}}$. We observed similar improvements in approximately 80\% of the test images, rendering the proposed technique significantly successful in improving the decoder performance with small number of training samples.


\begin{figure}[h]
\vspace{-1mm}
\centering
\footnotesize
\begin{tabular}{p{2.4cm}cccccccc} 
%\begin{tabular}{p{2.5cm}p{0.25cm}p{0.25cm}p{0.3cm}p{0.3cm}p{0.3cm}p{0.3cm}p{0.3cm}p{0.3cm}}
 %\hline

%	Model & (l,p,r)	& (l,p,r)& (l,p,r)& (l,p,r)& (l,p,r)& (l,p,r)& (l,p,r)& (l,p,r)\\[0.5ex]  
% \vspace*{-0.5cm} \hline
(a) Test image & \V{final_test/good_6_ori.png} & \V{final_test/good_7_ori.png}& \V{final_test/good_51_ori.png}& \V{final_test/good_114_ori.png} & \V{final_test/good_75_ori.png} & \V{final_test/good_318_ori.png} & \V{final_test/good_96_ori.png} & \V{final_test/good_261_ori.png}\\
 \cline{1-1}

(b) Recon by $M_{1,\mathrm{dec}}$ & \V{final_ori/good_6_ori.png} & \V{final_ori/good_7_ori.png}& \V{final_ori/good_51_ori.png}& \V{final_ori/good_114_ori.png} & \V{final_ori/good_75_ori.png} & \V{final_ori/good_318_ori.png} & \V{final_ori/good_96_ori.png} & \V{final_ori/good_261_ori.png}\\
 \cline{1-1}

%200 samples with unsharp masking& \V{final_ori_sharped/good_6_ori.png} & \V{final_ori_sharped/good_7_ori.png}& \V{final_ori_sharped/good_51_ori.png}& \V{final_ori_sharped/good_114_ori.png} & \V{final_ori_sharped/good_75_ori.png} & \V{final_ori_sharped/good_25_ori.png} & \V{final_ori_sharped/good_96_ori.png} & \V{final_ori_sharped/good_261_ori.png}\\
%  \cline{1-1}  

(c) Recon by $\widetilde{M}_{2,\mathrm{dec}}$ & \V{final_per_sharped/good_6_ori.png} & \V{final_per_sharped/good_7_ori.png}& \V{final_per_sharped/good_51_ori.png}& \V{final_per_sharped/good_114_ori.png} & \V{final_per_sharped/good_75_ori.png} & \V{final_per_sharped/good_318_ori.png} & \V{final_per_sharped/good_96_ori.png} & \V{final_per_sharped/good_261_ori.png}\\
%\vspace*{0.05cm}
%\hline

\end{tabular}
\caption{Results of the model $M_2$, trained with the newly generated dataset}
\label{fig:pertub1}
\vspace{-2mm}
\end{figure}

Fig. \ref{fig:pertub2} illustrates several instances where the proposed method still failed to capture the required subtle variations. Yet, even in these instances, the reconstructions of $\widetilde{M}_{2,\mathrm{dec}}$ demonstrates significant improvement over the reconstructions of $M_{1,\mathrm{dec}}$.

\begin{figure}[!h]
\vspace{-1mm}
\centering
\footnotesize
\begin{tabular}{p{3.5cm}ccc} 
 %\hline
	%Model & (l,p,r)	& (l,p,r)& (l,p,r)\\  
% \hline
(a) Test image & \W{final_test/bad_13_ori.png} & \W{final_test/bad_44_ori.png}& \W{final_test/bad_93_ori.png} \\
 %\hline
 \cline{1-1}
(b) Recon by $M_{1,\mathrm{dec}}$  & \W{final_ori/bad_13_ori.png} & \W{final_ori/bad_44_ori.png}& \W{final_ori/bad_93_ori.png} \\
 %\hline
 \cline{1-1}
%200 samples with unsharp masking & \V{good_15_ori.png}& \V{good_15_ori.png}& \V{good_15_ori.png} \\
% \hline  
%\cline{1-1}
(c) Recon by $\widetilde{M}_{2,\mathrm{dec}}$  & \W{final_per_sharped/bad_13_ori.png} & \W{final_per_sharped/bad_44_ori.png}& \W{final_per_sharped/bad_93_ori.png} \\
 %\hline
\end{tabular}
\caption{Instances where the model $M_2$ has not been succesful in capturing the subtle variations of the test image ---vertical line of G, bottom part of 3 ---}
\label{fig:pertub2}
\vspace{-2mm}
\end{figure}

GANs, VAEs and data augmentation techniques are alternatives to our proposed technique. Fig. \ref{fig:keyswscales} below, illustrates the generated images from a Conditional GAN (CGAN). However, at the generation phase, the new images are generated from random noise and that does not allow to apply specific perturbations, producing less realistic variations in images in comparison to what we do in the proposed method. Similarly, the reconstructions obtained when using our proposed technique are far better than it's alternatives in the low data regime, as shown by Fig. \ref{fig:agumented}, which contains the reconstructions obtained after training with the respective data augmentation technique. The alternatives produced little or reduced improvement, whereas our method produced visually significant ($\approx$ 1dB PSNR) improvement.

\begin{figure}
% \vspace{-7mm}
\centering
\includegraphics[height=6.5mm]{images/2.png}
\caption{Generated images from CGAN for label 2}
\label{fig:keyswscales}
\vspace{-4mm}
\end{figure}

\newcommand{\VI}[1]{\parbox[c]{0.8cm}{\includegraphics[scale=0.6]{images/#1}}}
%
\begin{figure}[!h]
%\begin{wrapfigure}{r}{0.55\linewidth}
\begin{tabular}{p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}} 
{\tiny Original} &  {\tiny \hspace{0.2em} Shift(S)} & {\tiny Rotation(R)} & {\tiny \hspace{0.6em} S \& R} & \tiny \hspace{0.4em} Noise & \tiny TextCaps \\
\VI{ori_7.png} & \VI{shift_7.png}& \VI{rotation_7.png} & \VI{shift_rot_7.png} & \VI{jitter_7.png} & \VI{good_7_ori.png}\\
%%
%%
\VI{ori_114.png} & \VI{shift_114.png}& \VI{rotation_114.png} & \VI{shift_rot_114.png} & \VI{jitter_114.png} & \VI{good_114_ori.png} \\
\end{tabular}
\caption{\small Comparison with other data augmentation techniques}

\label{fig:agumented}
\vspace{-4mm}
\end{figure}
%\end{wrapfigure}