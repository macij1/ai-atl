\begin{NiceTabular}{lccccc}
	\CodeBefore
	\Body
	\toprule
	& \multicolumn{5}{c}{\textbf{Commonsense Understanding}} \\
	\midrule
	& CommonSenseQA & PiQA & SiQA & OpenBookQA & Winogrande\\
\cmidrule{2-6}
	Llama 3 8B & \textbf{75.0 \scriptsize{$\pm$2.5}}& 81.0 \scriptsize{$\pm$1.8}& 49.5 \scriptsize{$\pm$2.2}& 45.0 \scriptsize{$\pm$4.4}& 75.7 \scriptsize{$\pm$2.0} \\
	Mistral 7B &71.2 \scriptsize{$\pm$2.6}& \textbf{83.0 \scriptsize{$\pm$1.7}}& 48.2 \scriptsize{$\pm$2.2}& 47.8 \scriptsize{$\pm$4.4}& \textbf{78.1 \scriptsize{$\pm$1.9}} \\
	Gemma 7B &74.4 \scriptsize{$\pm$2.5}& 81.5 \scriptsize{$\pm$1.8}& \textbf{51.8 \scriptsize{$\pm$2.2}}& \textbf{52.8 \scriptsize{$\pm$4.4}}& 74.7 \scriptsize{$\pm$2.0} \\
	\cmidrule{2-6}
	Llama 3 70B & \textbf{84.1 \scriptsize{$\pm$2.1}}& 83.8 \scriptsize{$\pm$1.7}& \textbf{52.2 \scriptsize{$\pm$2.2}}& 47.6 \scriptsize{$\pm$4.4}& 83.5 \scriptsize{$\pm$1.7} \\
	Mixtral 8$\times$22B &82.4 \scriptsize{$\pm$2.2}& \textbf{85.5 \scriptsize{$\pm$1.6}}& 51.6 \scriptsize{$\pm$2.2}& \textbf{50.8 \scriptsize{$\pm$4.4}}& \textbf{84.7 \scriptsize{$\pm$1.7}} \\
	\cmidrule{2-6}
	Llama 3 405B & \textbf{85.8 \scriptsize{$\pm$2.0}}& \textbf{85.6 \scriptsize{$\pm$1.6}}& \textbf{53.7 \scriptsize{$\pm$2.2}}& \textbf{49.2 \scriptsize{$\pm$4.4}}& 82.2 \scriptsize{$\pm$1.8} \\
	GPT-4 &--& --& --& --& 87.5 \scriptsize{$\pm$1.5} \\
	Nemotron 4 340B  &--& --& --& --& \textbf{89.5 \scriptsize{$\pm$1.4}} \\
	\bottomrule
\end{NiceTabular}
