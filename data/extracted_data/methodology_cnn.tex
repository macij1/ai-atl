\subsection{Comparison with CNN}
For the purpose of comparison, we propose a simple CNN architecture, comparable with the CapsNet architecture of the base model. However, it is important to note that CNN does not provide reconstruction capability as CapsNet, we evaluate this model only for comparison and completeness. The proposed CNN architecture consists of four main layers and designed to have maximum number of parameters possible with highest accuracy.

The first layer of the CNN is identical to the CapsNet base model, which is a convolutional layer with 256, 9x9 kernels with a stride of 1 and ReLU activation. The second layer is somewhat similar to the Primary Capsule layer in the base model, which has the same convolutional layer of 128, 9x9 kernels with a stride of 1 and ReLU activation, but followed by a pooling layer with filters of size 2x2 of max pooling. The third layer is designed to match the DigitCaps layer with a convolutional layer followed by a fully connected layer. This layer consists of a convolutional layer of 256, 3x3 kernels with a stride of 1 and ReLU activation, a pooling layer with filters of size 2x2 of max pooling, and a fully connected layer of 1024 outputs with ReLU activation. A flatten layer is added in between pooling and fully connected layers. 

Two fully connected layers are included in the fourth and final layer. The first fully connected layer outputs a vector of size 512 with ReLU activation and the output size of the final fully connected layer with sigmoid activation is the number of classes used. 