\subsubsection{Speech Generation}
To support real-time processing, the prosody model employs a lookahead mechanism that considers a fixed number of future phones and a variable number of future tokens. This ensures consistent lookahead while processing incoming text, which is crucial for low-latency speech synthesis applications.

\textbf{Training.} We develop a dynamic alignment strategy utilizing causal masking to facilitate streamability in speech synthesis. This strategy incorporates a lookahead mechanism for a fixed number of future phones and a variable number of future tokens, aligning with the chunking process during text normalization (Section~\ref{sec:data:tts}). For each phone, the token lookahead includes the maximum number of tokens defined by the chunk size, resulting in variable lookahead for Llama embeddings but fixed lookahead for phonemes.

The Llama 3 embeddings are sourced from the Llama 3 8B model, which remains frozen during the training of the Prosody Model. The input phone-rate features include both linguistic and speaker/style controllability elements. The model training is conducted with a batch size of 1,024 utterances, each with a maximum length of 500 phones. We employ a learning rate of \(9 \times 10^{-4}\) using the AdamW optimizer, training over 1 million updates with a learning rate warmup for the first 3,000 updates, following a cosine schedule.

\textbf{Inference.} During inference, the same lookahead mechanism and causal masking strategy are employed to ensure consistency between training and real-time processing. The PM handles incoming text in a streaming manner, updating the input phone by phone for phone-rate features and chunk by chunk for token-rate features. The new chunk input is updated only when the first phone for that chunk is current, maintaining the alignment and lookahead as during training.

For prosody target prediction, we employ a delayed pattern approach \citep{kharitonov2021text}, which enhances the modelâ€™s ability to capture and reproduce long-range prosodic dependencies. This approach contributes to the naturalness and expressiveness of the synthesized speech, ensuring low-latency and high-quality output.
