%\subsection{Using lower number of training samples per class} %\label{sec:meth_low_data}

First, we train the proposed model with the full training sets and evaluate its performance. Subsequently, in an effort to address the issue of lack of high number of training samples in character recognition and similar tasks as elaborated in section \ref{sect:intro}, we attempt to achieve the state-of-the-art performance using 200 training samples per class, using the same network.

%When we observe the reconstruction output of the decoder network with 200 training points it does not give similar results as in \cite{sabour2017dynamic}. Therefore, in order to increase the number of training data points, we propose an perturb data generation. By perturbing reconstructed data from the reconstruction network to change the properties of the image. Therefore new perturb image will not be as same as the reconstructed image. This will reduce the over fitting by training with same data points over and over again.

By examining the results of the above section with low number of training samples, as elaborated in Section \ref{sec:results_classification}, we observed that even though the capsule network performance achieved the state-of-the-art, the decoder network fails to achieve acceptable reconstruction. The most obvious solution to enhancing the performance of the decoder network is to increase the number of training samples, by generating new training samples from the samples available in the original (reduced) training set. Therefore, we propose a novel method of generating new training samples by augmenting original training samples with the aid of the concept of instantiation parameters in the CapsNets, as described by the following Section \ref{sec:meth_perturb}

%It is essential to emphasize that this augmentation is significantly different from the pre-augmentations such as rotation, horizontal or vertical shift, flip and etc, that are typically performed in deep learning tasks.