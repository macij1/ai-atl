\section{Related Work}
\label{sect:related}
MNIST \cite{lecun1998mnist} is the widely used benchmark for the handwritten digit recognition task. Multiple works \cite{article,DBLP:journals/corr/abs-1202-2745,4668644,Ranzato:2006:ELS:2976456.2976599,5459469} have used CNN models on MNIST dataset and have achieved results in excess of 99\% accuracy. 
%In this paper we have used Extension MNIST(EMNIST) data set from \cite{2017arXiv170205373C} which contains handwritten English letters and digits. 
Apart from digit recognition, several attempts \cite{2017arXiv170205373C,2017arXiv170909161D} have been made in handwritten character recognition with EMNIST datasets \cite{2017arXiv170205373C}.
A bidirectional neural network is introduced in \cite{DBLP:journals/corr/abs-1803-01900} which is capable of performing both image classification and image reconstruction by adding a style memory to the output layer of the network. 

The idea of a capsule was introduced in 2011 by \cite{hinton2011transforming}, as a transforming autoencoder. With a three layered CapsNets architecture, and by training the network using dynamic routing, authors of \cite{sabour2017dynamic} have achieved 0.25\% error rate on the MNIST dataset. This architecture consists of a primary capsule, which was built by stacking convolutional layers, and a fully connected capsule, which uses routing by agreement between higher level capsules and lower level capsules. We draw intuition for this paper from the concept of instantiation parameters proposed in \cite{hinton2011transforming}, while emphasizing that our work is significantly novel and different from \cite{hinton2011transforming}.

%Auto-encoders are the neural network solution for the image reconstruction \cite{554192}. Tan \textit{et al.} \cite{4564577} have compared three type of autoencoders namely traditional autoencoder with Restricted Boltzmann Machine (RBM), the stacked autoencoder without RBM and the stacked autoencoder with RBM and conclude that stacked autoencoder with RBM outperforms the other models with 1.231 mean square error on MNIST dataset. Further, Tian \textit{et al.} \cite{6628836} have perform character reconstruction on  ICDAR 2003 dataset through medial axis technique. 62.15\% accuracy was achieved by evaluating the reconstructed images using Tesseract optical character recognizer \cite{sarma2009tesseract}. 
% Since the output of the CapsNet comprises the instantaneous parameters of the input data, suitable decoder network will be able to reconstruct the input image using those instantaneous parameters. Further details on the decoder network will be presented in the next section.

% Decoder network in \cite{sabour2017dynamic} uses Mean Squared Error, which is commonly used as a loss calculation function \cite{6247952,NIPS2008_3506,7025371}. Structural similarity measurement is proposed as a replacement for the mean square error loss function in \cite{Wang:2004:IQA:2319031.2320551}, which is better at capturing spatial relationships.

We identified two main solutions in the literature to the low data issue, namely one-shot learning and new data generation. An example of the former is the Siamese networks as proposed in \cite{Koch2015SiameseNN}. A one-shot learning deep model was proposed by Bertinetto \textit{et al.}\cite{DBLP:journals/corr/BertinettoHVTV16}, where they used a second network to predict the parameters of the first network. Since one-shot learning solutions are mostly application-specific, we turn to a new data generation approach.

Existing literature offers several successful data generation techniques. Although GANs \cite{goodfellow2014generative} can be used to generate data, a basic form of a GAN network will not be sufficient to augment the dataset for training, since it can not generate labelled data, unless a separate GAN is trained per class.
Another potential choice which has image generation capabilities, Variational Autoencoders (VAEs) \cite{doersch2016tutorial} have similar problems. VAEs represent all the images as 1D vectors,
whereas capsule networks have dedicated dimensions for each class. As a result, when VAEâ€™s 1D vectors are perturbed, there is a high probability that those changes affect multiple classes. 
Data augmentation techniques such as jittering and flipping (not
suitable for characters) offer limited amount of simple augmentation. Thus, they can not offer complex and subtle variations that are more closer to the human variations. A comprehensive comparison of our results with these techniques are provided in Section \ref{sec:results_perturb}.