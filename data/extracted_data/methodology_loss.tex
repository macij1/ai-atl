\subsection{Various Reconstruction Loss Functions} \label{sec:meth_loss}
We investigate the effect on reconstruction based on the loss function used for reconstruction in a capsule network, in order to identify a well-suited reconstruction loss function for the TextCaps model.  First, we study the variations on reconstruction with different loss functions for different number of training samples on the EMNIST-Balanced dataset, and then we extend our analysis to various combinations of loss functions. In this analysis, both spatial and structural similarity measures are used as reconstruction  loss functions. 
 
Since different loss functions we use produce outputs in different scales, it is not possible compare the losses directly. Therefore, we use Peak Signal-to-Noise Ratio (PSNR) given by (\ref{psnr}), as an independent (of reconstruction loss functions) measure, to determine the quality of reconstructed images. 
\vspace{-4mm}
\begin{equation}
PSNR = 10\log_{10} \left(\frac{MAX_i^2}{MSE}\right)
\label{psnr}
\vspace{-1mm}
\end{equation}

where $MAX_i$ is the maximum possible pixel value of the image ($1$ in our case) and $MSE$ is the Mean Squared Error between the test and reconstructed images. 

Let $x(p)$ be the intensity of the $p^{th}$ reconstructed pixel and $y(p)$ be the intensity of the $p^{th}$ true input pixel and $N$ be the total number of pixels.

%\medskip
\vspace{-0.4cm}
\subsubsection{MSE}

Following Sabour \textit{et al.} \cite{sabour2017dynamic}, we use $MSE$, as the loss function for reconstruction, defined by,
\vspace{-0.2cm}
\begin{equation}
MSE = \frac{1}{N} \sum_{i=1}^{N} (x(p)-y(p))^2
\label{mse}
\end{equation}

\vspace{-0.9cm}
%\medskip
\subsubsection{$L_1$ Norm}

To remove artifacts introduced by $MSE$, we consider $L_1$ norm as a loss function which is defined by,
\vspace{-0.3cm}
\begin{equation}
L_1 = \frac{1}{N} \sum_{i=1}^{N} |x(p)-y(p)|
\label{mae}
\end{equation}

\vspace{-0.9cm}
%\medskip
\subsubsection{SSIM}
%\DeclareMathOperator{\SSIM}{SSIM}
$L_1$ and $MSE$ do not capture the spatial relationship between pixels. We use $SSIM$ proposed in \cite{Wang:2004:IQA:2319031.2320551} to capture spatial relationship between the input image and reconstructed image. $SSIM$ for $x,y$ and the loss function for $SSIM$, structural dissimilarity ($DSSIM$), are defined by,
\vspace{-0.1cm}
\begin{equation}
%\scriptsize \begin{align}
%SSIM(x,y) = \frac{(2\mu_x\mu_y + C_1)} {(\mu_x^2 + \mu_y^2+C_1)} .\frac{ (2 \sigma _{xy} + C_2)} {(\sigma_x^2 + \sigma_y^2+C_2)} \ \ , \ \ DSSIM = \frac{1}{N} \sum_{i=1}^{n} 1- SSIM(p)
%\end{align}
%\normalsize
SSIM(x,y) = \frac{(2\mu_x\mu_y + C_1)} {(\mu_x^2 + \mu_y^2+C_1)} .\frac{ (2 \sigma _{xy} + C_2)} {(\sigma_x^2 + \sigma_y^2+C_2)}
\label{ssim}
\end{equation}
\vspace{-0.3cm}
\begin{equation}
DSSIM = \frac{1}{N} \sum_{i=1}^{n} 1- SSIM(p)
\label{dssim}
\end{equation}
where $\mu_x$, $\mu_y$ and $\sigma_x^2$, $\sigma_y^2$ are the means and variances and $\sigma _{xy}^2$ is the covariance of reconstructed and true input pixel intensities.
$C_1=(K_1L)^2$ and $C_2=(K_2L)^2$ where $L$ is the dynamic range of the pixel values (typically, $2^m -1$, where $m$ is the number of bits per pixel) and $K_1$, $K_2$ are small constants ($K_1=0.01$ and $K_2=0.03$).

\vspace{-0.3cm}
%\smallskip
\subsubsection{Binary Cross-Entropy (BCE)}
$BCE$ is often used as a measure to identify the difference between two distributions, which is defined by,
\vspace{-0.3cm}
\begin{equation}
BCE = - \frac{1}{N} \sum_{i=1}^{n} [y(p)\log(x(p)) + (1-y(p))\log(1-x(p))]
\label{bce}
\end{equation}

\vspace{-0.5cm}
\subsubsection{Combinations of Loss Functions}
To combine two loss functions, rather than linearly combining two loss equations mathematically, we propose a method which combines two reconstructed images together. We slightly modify the CapsNet decoder network using two decoders, one for each loss function and generate two separate reconstruction outputs. Then we compare the absolute values of the difference of each pixel value between the two reconstructed outputs and the test images independently, and assign the pixel value which is closer to the test image to the final reconstructed output. Different loss function combinations we use here for two decoders are $L_1$  \&  $DSSIM$, $L_1$  \&  $BCE$, $MSE$  \&  $DSSIM$, $MSE$  \&  $BCE$ and $BCE$  \&  $DSSIM$.

%\begin{figure}[!h]
%\centering
%\includegraphics[scale=0.35]{figures/2decoder.png}
%\caption{We use two decoder networks which trained with different loss functions. Then we fuse both reconstructed image, to get more accurate representation of input image. }
%\label{fig:2decoder}
%\end{figure}

%Different loss function combinations we use here are follows:
%
%\begin{itemize}
%\item $L_1$  \&  $DSSIM$
%\item $L_1$  \&  $BCE$
%\item $MSE$  \&  $DSSIM$
%\item $MSE$  \&  $BCE$
%\item $BCE$  \&  $DSSIM$
%\end{itemize}

