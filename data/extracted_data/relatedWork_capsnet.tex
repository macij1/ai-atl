\section{Capsule Networks and Dynamic Routing Algorithm}
\label{sect:related_caps}
A capsule is a group of neurons whose activity vectors represent not only the probability of existence of a certain entity, but a set of instantiation parameters \cite{hinton2011transforming}. The instantiation parameters can include pose (position, size, orientation), deformation, velocity, albedo, hue, texture and etc. \cite{sabour2017dynamic}. Hence, a capsule can be said to have the ability to learn a set of properties of a particular entity, rather than learning to detect the presence of that entity, similar to CNN. \jathu{rewrite}

Once pixel intensities have been converted into the outputs of a set of active, first-level capsules each of which produces an explicit representation of the pose of its visual entity. these low level capsules used to learn part-whole relationship and build up high level capsules.

An important notion in utilizing part-whole relationship for object recognition is that, even though the instantiation parameters for part entities and whole entities can vary for different inputs, the spatial relationship between a part entity and its whole entity remains static. Hence, part-whole relationship is viewpoint invariant \cite{hinton2011transforming}.

Consider that a capsules in layer $l$ learns part entities whereas the capsules in layer $l+1$ learns the whole entities, which are made from the part entities in layer $l$. Each output vector $u_i$ of layer $l$, represents the instantiation parameters of the part entity. capsules in layer $l+1$ learn the part-whole relationship and build a whole entity capsule $v_j$ from $u_i, i \in [N_l]$. where $N_l, N_{l+1}$ are the number of capsules in layer $l, l+1$ respectively.

% Capsules use high-dimensional coincidence filtering: a familiar object can be detected by looking for agreement between votes for its pose matrix. \cite{hinton2018matrix}

In the perspective of the capsule $j$, it can receive multiple predictions from the lower layer. Similarly, in the perspective of Capsule $i$, it has a choice of sending its output to multiple capsules in the higher layer. The fact that the output of a capsule outputs a more meaningful activity vector, rather than merely an activation value, allows the output to be dynamically routed to high level capsules which agree more with it. Such routing mechanisms are termed as \textit{Routing-by-agreement}.

\subsubsection{Dynamic Routing Algorithm}

part-whole spatial relationship between the capsule $i$ in the layer $l$ and the capsule $j$ in the layer $l+1$ is learned by the transformation matrix $W_{ij}$ during back propagation. Hence, from equation[\ref{eq:pred}], we can obtain a prediction for the existence and pose of the part entity in layer $l+1$ from $\hat{u}_{j|i}$. 

\begin{equation} \label{eq:pred}
\hat{u}_{j|i} = W_{ij} \times u_i
\end{equation}
\begin{equation} \label{eq:sum}
s_{j} = \sum_{i}^{} c_{ij}\hat{u}_{ij}
\end{equation}


$s_j$ can be interpreted as the weighted sum of predictions from the capsules in layer $l$. Hence, the output of the capsule $j$, $v_j$ can be calculated with the aid of $s_j$, according to eq[\ref{eq:vj}].  Squash function is used to keep the capsule vector within unit length while preserving orientation, so its length will represent the probability of the existence of an entity.

\begin{equation} \label{eq:vj}
v_{j} = \frac{||s_j||^2}{1+||s_j||^2} \frac{s_j}{||s_j||}
\end{equation}


The subsequent task is to route the outputs of the capsules in layer $l$ as the inputs of capsules in layer $l+1$. which requires to update $c_{ij}$ at each routing.

\begin{equation} \label{eq:softmax}
c_{ij} = \frac{exp(b_{ij})}{ \sum_{j}^{} exp(b_{ik})}
\end{equation}
\begin{equation} \label{eq:bij}
b_{ij} = b_{ij}+\hat{u}_{ij} \cdot v_{j}
\end{equation}
$b_{ij}$ is initialized to zero is to provide equal value to $c_{ij}$ in first routing. As the procedure progresses, the $c_{ij}$ will be eventually updated with $a_{ij} = \hat{u}_{ij} \cdot v_{j}$. here $a_{ij}$ corresponding to the argument between $v_j$ and $\hat{u}_{ij}$, hence routing by argument.