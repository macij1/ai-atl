\section{Introduction}
\label{sect:intro}

%Handwritten character recognition, although nearly solved for well-known languages,is still unsolved for many languages due to the lack of substantially large, labeled handwrittencharacter data. The size of the dataset needs to be sufficiently large to be ableto train deep learning algorithms \cite{Krizhevsky:2012:ICD:2999134.2999257}.

%Systems that can work with small sets of data---linear classifiers, K-nearest neighbors, non-linear classifiers, Support Vector Machines (SVMs)\cite{lee1991handwritten}---have been used with some success. These conventional models lag behind the human level performance. However, in the recent years, deep learning techniques have shown prominent results in handwritten character recognition tasks \cite{cirecsan2010deep}.

Handwritten character recognition is a nearly solved problem for many of the mainstream languages thanks to the recent advancements in deep learning models \cite{cirecsan2010deep}. Nonetheless, for many other languages, handwritten digit recognition remains a challenging problem due to the lack of sufficiently large labeled datasets that are essential to train deep learning models \cite{Krizhevsky:2012:ICD:2999134.2999257}. While conventional models such as linear classifiers, K-nearest neighbors, non-linear classifiers, and Support Vector Machines (SVM)  \cite{lee1991handwritten} can be used for this task, they are not able to achieve the near human level performances provided by deep learning models. Convolutional Neural Networks (CNN) have achieved state-of-the-art results due to their ability to encode deep features and spatial understanding. Although CNNs are good at understanding low level and high level features in images, by doing so, they lose valuable information at pooling layers. CNNs require large number of training samples (usually in the scale of thousands or tens of thousands per class) to train and classify images successfully. As a result, there is a strong interest in training CNNs with a lesser number of training samples.
% \textcolor{red}{CNN has a large learning capacity hence it is suitable for image classification without any prior knowledge on training data}\jathu{rephrase}. 
% With the ability of shift invariance, CNN can ignore scale variances of the input data. Yet CNNs consist of several drawbacks, they disregard the spatial relationship in the input data and need thousands of data points to achieve good performance.

In this paper, we propose a technique which tackles this problem of the labeled dataset being small in size, with the aid of Capsule Networks (CapsNets) \cite{sabour2017dynamic}. We exploit their ability to augment data just by manipulating the instantiation parameters \cite{hinton2011transforming}. CapsNets learn the properties of an image---in this case a character---in addition to its existence. This makes them useful in learning to recognize characters with a less amount of labeled data. Our architecture is based on the CapsNet architecture proposed by Sabour \textit{et al.} \cite{sabour2017dynamic}, which comprises a capsule network and a fully connected decoder network. We replace the decoder network with a deconvolutional network while doing minor alterations to the capsule network. By adding a controlled amount of noise to the instantiation parameters that represent the properties of an entity, we transform the entity to characterize actual variations that happen in reality.  This results in a novel data generation technique, much more realistic than augmenting data with affine transformations. As the reconstruction accuracy is also important in many contexts, we present an empirically appropriate strategy of combining loss functions which significantly improves the reconstruction. 
Our system achieves results that are on-par with the state-of-the-art with just 200 data points per class, while achieving even better results with larger volumes of training data. 

%Capsule networks (CapsNet)\cite{sabour2017dynamic}, in contrast, solves this problem by learning the properties of an entity in addition to its existence.  These show the ability to learn from a less amount of data, making them useful for learning to recognize characters of with a less amount of labeled data.   

%\cite{sabour2017dynamic} have proposed Capsule Network(CapsNet) which eliminates drawbacks of CNN such as equivariance and usage of pooling. The instantiation parameters can include pose (position, size, orientation), deformation, velocity, albedo, hue, texture \cite{hinton2011transforming}. A capsule have the ability to learn a set of properties of a particular entity as well as its existence, while CNNs learns only the presence of an entity. Capsule networks has shown the ability to learn from less amount of data, that makes a perfect candidate for this problem. 

% Once pixel intensities have been converted into the outputs
% of a set of active, first-level capsules each of which produces
% an explicit representation of the pose of its visual entity. It
% is relatively easy to see how larger and more complex visual
% entities can be recognized by using agreements of the poses
% predicted by active, lower-level capsules.

%In this paper, we propose a novel technique which tackles above mentioned problem with the aid of CapsNet using its ability to augment data just by manipulating the instantiation parameters\cite{hinton2011transforming}. The key contributions of this paper are as follows:
The key contributions of this paper are as follows:

\begin{itemize}[noitemsep,nolistsep]
\item  We outperform the state-of-the-art results in EMNIST-letters, EMNIST-balanced and EMNIST-digits character datasets, by training our
system on all the training samples available.

\item We evaluate the proposed architecture on a non-character dataset, Fashion-MNIST, to ensure the
flexibility and robustness.  We achieve very good results with 200 training samples and achieve the state-of-the-art with the full dataset.

\item We propose a novel technique for training capsule networks with small number
of training samples, as small as 200 per class, and keeping the same set of
test samples, while achieving the state-of-the-art performance. Our method
require only 10\% of data necessary for a state-of-the-art system, to produce similar results.
 


\item  We propose and evaluate several variations to the decoder network and analyze
its performance with different loss functions to provide a strategy to
select a suitable combination of loss functions.
 

\end{itemize}

Rest of the paper is organized as follows: in Section \ref{sect:related} we discuss the related works, and in Section \ref{sec:meth_overview} we explain our methodology. Subsequently, we discuss our results in Section \ref{sec:results}.
