{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\seyon\\AppData\\Local\\Temp\\ipykernel_21144\\93926138.py:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  with open(\"..\\data\\ml_papers.json\", \"r\") as file:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24988"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "ml_papers = []\n",
    "with open(\"..\\data\\ml_papers.json\", \"r\") as file:\n",
    "    ml_papers = json.load(file)\n",
    "\n",
    "len(ml_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0704.0671',\n",
       " 'submitter': 'Maxim Raginsky',\n",
       " 'authors': 'Maxim Raginsky',\n",
       " 'title': 'Learning from compressed observations',\n",
       " 'comments': '6 pages; submitted to the 2007 IEEE Information Theory Workshop (ITW\\n  2007)',\n",
       " 'journal-ref': None,\n",
       " 'doi': '10.1109/ITW.2007.4313111',\n",
       " 'report-no': None,\n",
       " 'categories': 'cs.IT cs.LG math.IT',\n",
       " 'license': None,\n",
       " 'abstract': '  The problem of statistical learning is to construct a predictor of a random\\nvariable $Y$ as a function of a related random variable $X$ on the basis of an\\ni.i.d. training sample from the joint distribution of $(X,Y)$. Allowable\\npredictors are drawn from some specified class, and the goal is to approach\\nasymptotically the performance (expected loss) of the best predictor in the\\nclass. We consider the setting in which one has perfect observation of the\\n$X$-part of the sample, while the $Y$-part has to be communicated at some\\nfinite bit rate. The encoding of the $Y$-values is allowed to depend on the\\n$X$-values. Under suitable regularity conditions on the admissible predictors,\\nthe underlying family of probability distributions and the loss function, we\\ngive an information-theoretic characterization of achievable predictor\\nperformance in terms of conditional distortion-rate functions. The ideas are\\nillustrated on the example of nonparametric regression in Gaussian noise.\\n',\n",
       " 'versions': [{'version': 'v1', 'created': 'Thu, 5 Apr 2007 02:57:15 GMT'}],\n",
       " 'update_date': '2016-11-15',\n",
       " 'authors_parsed': [['Raginsky', 'Maxim', '']]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_papers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "dois = []\n",
    "categories = []\n",
    "\n",
    "for paper in ml_papers:\n",
    "    doi = paper['doi']\n",
    "    dois.append(doi)\n",
    "    categories.append(paper['categories'])\n",
    "\n",
    "print(len(doi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
